{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d519082a-3afc-44a8-b66e-6b0aab37328f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Get the storage link "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cfb9e894-7b70-4186-a40f-f1a76af2f032",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "adls_path =  f\"abfss://raw-data@storageforchurnproject.dfs.core.windows.net/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8bfdae09-4004-4654-950b-73250391ade6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "container_name = \"raw-data\"\n",
    "file_name = \"WA_Fn-UseC_-Telco-Customer-Churn.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f376c305-5df4-44d7-acaa-55422d3ff24a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Data EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8f642f23-5d6d-4b4e-9a21-846df4f47be8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Display sample of the data set using the dispaly function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b85e3db-4a57-4fb4-944c-9737bf1e3177",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.csv(f\"{adls_path}/{file_name}\", header=True, inferSchema=True)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f7dafc00-1863-4869-abbc-8f76aba70ea9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "38346143-e9c5-4be2-bc24-53873922a8cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Check for missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed41004e-ebc4-4c98-bdd0-252f77f6d5be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.describe().display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87af5346-ec8a-4360-810f-6af21e21729f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, when\n",
    "\n",
    "# The 'TotalCharges' column has spaces for new customers. Let's treat them as 0.\n",
    "# First, cast to a numeric type. Errors will become null.\n",
    "df_clean = df.withColumn(\"TotalCharges\", col(\"TotalCharges\").cast(\"double\"))\n",
    "\n",
    "# Replace nulls (which were originally spaces) with 0\n",
    "df_clean = df_clean.na.fill(value=0, subset=[\"TotalCharges\"])\n",
    "\n",
    "# Drop the customerID column as it's just an identifier\n",
    "df_clean = df_clean.drop(\"customerID\")\n",
    "\n",
    "# Convert the label column 'Churn' into a numeric format (0 or 1)\n",
    "df_clean = df_clean.withColumn(\"label\", when(col(\"Churn\") == \"Yes\", 1).otherwise(0))\n",
    "\n",
    "print(\"Data successfully cleaned.\")\n",
    "display(df_clean.select(\"TotalCharges\", \"Churn\", \"label\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87e74ea6-13c6-43a0-a7c0-58672e4a13d0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.sql.types import StringType, IntegerType, DoubleType\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "categorical_cols = [field.name for field in df_clean.schema.fields if isinstance(field.dataType, StringType) and field.name != 'Churn']\n",
    "numerical_cols = [field.name for field in df_clean.schema.fields if isinstance(field.dataType, (IntegerType, DoubleType)) and field.name != 'label']\n",
    "\n",
    "# --- Pipeline Stages ---\n",
    "\n",
    "# Stage 1: StringIndexer to convert categorical strings to numeric indices\n",
    "indexers = [StringIndexer(inputCol=c, outputCol=f\"{c}_index\", handleInvalid=\"skip\") for c in categorical_cols]\n",
    "\n",
    "# Stage 2: OneHotEncoder to convert indexed categories into a binary vector\n",
    "# Note: We are not using OneHotEncoder in the final pipeline for simplicity with Logistic Regression,\n",
    "# but this is where you would typically add it. VectorAssembler can handle the indexed columns directly.\n",
    "\n",
    "# Stage 3: VectorAssembler to combine all feature columns into a single vector\n",
    "assembler_inputs = [f\"{c}_index\" for c in categorical_cols] + numerical_cols\n",
    "assembler = VectorAssembler(inputCols=assembler_inputs, outputCol=\"features\")\n",
    "\n",
    "# Create the preprocessing pipeline\n",
    "preprocessing_pipeline = Pipeline(stages=indexers + [assembler])\n",
    "\n",
    "# Fit and transform the data\n",
    "transformed_df = preprocessing_pipeline.fit(df_clean).transform(df_clean)\n",
    "\n",
    "# Display the result\n",
    "display(transformed_df.select(\"features\", \"label\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a239248-0750-4e95-9170-a2c6a07afe71",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "(train_data, test_data) = transformed_df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "print(f\"Training set count: {train_data.count()}\")\n",
    "print(f\"Test set count: {test_data.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2056b736-39bf-438a-b7ed-5c67a1e299b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Cell 7: Train the Machine Learning Model with MLflow\n",
    "import mlflow\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# Start an MLflow run. Everything within this 'with' block will be logged.\n",
    "with mlflow.start_run(run_name=\"Logistic Regression Churn\") as run:\n",
    "    # Create the Logistic Regression model\n",
    "    lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\")\n",
    "\n",
    "    # Train the model\n",
    "    lr_model = lr.fit(train_data)\n",
    "\n",
    "    # Log the model itself as an artifact\n",
    "    mlflow.spark.log_model(lr_model, \"churn-model\")\n",
    "\n",
    "    # Log parameters (optional, but good practice)\n",
    "    mlflow.log_param(\"regParam\", lr.getRegParam())\n",
    "    mlflow.log_param(\"elasticNetParam\", lr.getElasticNetParam())\n",
    "\n",
    "    print(\"Model training complete and logged to MLflow.\")\n",
    "    # Store the run_id for later use\n",
    "    run_id = run.info.run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d26127b-d43d-4cc8-8620-c01b9e14a4f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Cell 8: Make Predictions and Log Metrics to MLflow\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = lr_model.transform(test_data)\n",
    "\n",
    "# --- Log Metrics to the same MLflow Run ---\n",
    "# Use the Binary evaluator for AUC\n",
    "evaluator_auc = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
    "auc = evaluator_auc.evaluate(predictions)\n",
    "mlflow.log_metric(\"test_auc\", auc)\n",
    "\n",
    "# Use the Multiclass evaluator for other metrics like accuracy, F1\n",
    "evaluator_f1 = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "f1_score = evaluator_f1.evaluate(predictions)\n",
    "mlflow.log_metric(\"test_f1_score\", f1_score)\n",
    "\n",
    "evaluator_acc = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator_acc.evaluate(predictions)\n",
    "mlflow.log_metric(\"test_accuracy\", accuracy)\n",
    "\n",
    "print(f\"Area Under ROC Curve (AUC) = {auc}\")\n",
    "print(f\"F1 Score = {f1_score}\")\n",
    "print(f\"Accuracy = {accuracy}\")\n",
    "\n",
    "# End the MLflow run (optional, as 'with' block handles it, but good for clarity)\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b2dd6a5e-1860-4a15-9da6-1ff039a5a0bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "(Clone) churn Prediction",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
